agents:
  provider: gcp
  image: family/elasticsearch-ubuntu-2004
  machineType: n2-standard-8
  diskType: pd-ssd
  diskSizeGb: 100
  useVault: false

steps:
  - label: intake
    command: ./gradlew check -x :elasticsearch-spark-20:integrationTest -x :elasticsearch-spark-13:integrationTest
    timeout_in_minutes: 240

  - group: spark-scala
    steps:
      - label: 'spark-{{matrix.SPARK_VERSION}} / scala-{{matrix.SCALA_VERSION}}'
        command: ./gradlew :elasticsearch-spark-{{matrix.SPARK_VERSION}}:integrationTest -Pscala.variant={{matrix.SCALA_VERSION}}
        timeout_in_minutes: 180
        matrix:
          setup:
            SPARK_VERSION:
              - '20'
              - '30' # TODO, should this actually be 30?
            SCALA_VERSION:
              - '2.10.6'
              - '2.11.8'

  # TODO
  # - wait
  # - label: dra-snapshot
  #   command: TODO
  #   timeout_in_minutes: TODO
# before: 8.9
# all spark versions

# 7.17
# spark 1.x, 2.x, 3.x
# scala, 2.10, 2.11 for 1.x
# 2.10,

# es-hadoop-build
# periodic daily

# all pipelines same split out stuff
# groupings of spark/scala versions

# use script (python?) to pull all variants from spark/core/build.gradle
# then grab full scala versions from gradle.properties
# then generate the pipeline in json
