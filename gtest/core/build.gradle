import org.elasticsearch.hadoop.gradle.scala.SparkVariantPlugin

/*
 * Licensed to Elasticsearch under one or more contributor
 * license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright
 * ownership. Elasticsearch licenses this file to you under
 * the Apache License, Version 2.0 (the "License"); you may
 * not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */

apply plugin: 'java'
apply plugin: 'scala'
apply plugin: 'spark.variants'

repositories {
    mavenCentral()
}

group = 'org.elasticsearch.spark'
version = '1.0'

def spark24 = "2.4.4"
def spark20 = "2.2.3"
def spark13 = "1.6.2"

def scala212s = '2.12'
def scala211s = '2.11'
def scala210s = '2.10'

def scala212 = '2.12.8'
def scala211 = '2.11.12'
def scala210 = '2.10.7'

java {
    withJavadocJar()
    withSourcesJar()
}

sparkVariants {
    capabilityGroup 'org.elasticsearch.spark.variant'
    setDefaultVariant "spark24scala212", spark24, scala212
    addFeatureVariant "spark24scala211", spark24, scala211
    addFeatureVariant "spark20scala210", spark20, scala210
    addFeatureVariant "spark13scala211", spark13, scala211
    addFeatureVariant "spark13scala210", spark13, scala210

    featureVariants { SparkVariantPlugin.SparkVariant v ->
        tasks.getByName(v.testTaskName()) {
            excludes = ["**/Abstract*.class"]
            ignoreFailures = false
//            executable = "${project.ext.get('runtimeJavaHome')}/bin/java"
            minHeapSize = "256m"
            maxHeapSize = "2g"
        }
    }

    all {  SparkVariantPlugin.SparkVariant v ->
        configurations { ConfigurationContainer container ->
            Configuration embedded = container.create(v.configuration("embedded"))
            container.getByName(v.configuration("implementation")) { Configuration conf ->
                conf.extendsFrom(embedded)
            }
        }

        dependencies { DependencyHandler d ->
            d.add(v.configuration("implementation"), "org.scala-lang:scala-library:${v.scalaVersion}")
            d.add(v.configuration("implementation"), "org.scala-lang:scala-reflect:${v.scalaVersion}")
            d.add(v.configuration("implementation"), "org.apache.spark:spark-core_${v.scalaMajorVersion}:${v.sparkVersion}") {
                exclude group: 'javax.servlet'
                exclude group: 'org.apache.hadoop'
            }
            d.add(v.configuration("test", "implementation"), "junit:junit:4.12")
        }
    }
}
