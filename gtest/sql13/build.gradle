import org.elasticsearch.hadoop.gradle.scala.SparkVariantPlugin

import java.util.concurrent.Callable

/*
 * Licensed to Elasticsearch under one or more contributor
 * license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright
 * ownership. Elasticsearch licenses this file to you under
 * the Apache License, Version 2.0 (the "License"); you may
 * not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */

apply plugin: 'java'
apply plugin: 'scala'
apply plugin: 'spark.variants'

repositories {
    mavenCentral()
}

group = 'org.elasticsearch.spark'
version = '1.0'

def spark24 = "2.4.4"
def spark20 = "2.2.3"
def spark13 = "1.6.2"

def scala212s = '2.12'
def scala211s = '2.11'
def scala210s = '2.10'

def scala212 = '2.12.8'
def scala211 = '2.11.12'
def scala210 = '2.10.7'

java {
    withJavadocJar()
    withSourcesJar()
}

sparkVariants {
    capabilityGroup 'org.elasticsearch.spark.sql.variant'
    setDefaultVariant "spark13scala211", spark13, scala211
    addFeatureVariant "spark13scala210", spark13, scala210

    featureVariants { SparkVariantPlugin.SparkVariant v ->
        tasks.getByName(v.testTaskName()) {
            excludes = ["**/Abstract*.class"]
            ignoreFailures = false
//            executable = "${project.ext.get('runtimeJavaHome')}/bin/java"
            minHeapSize = "256m"
            maxHeapSize = "2g"
        }
    }

    all { SparkVariantPlugin.SparkVariant v ->
        configurations { ConfigurationContainer container ->
            container.create(v.configuration("embedded")) {
                canBeConsumed = false
                canBeResolved = true
            }
        }

        dependencies {
            add(v.configuration("implementation"), "org.scala-lang:scala-library:${v.scalaVersion}")
            add(v.configuration("implementation"), "org.scala-lang:scala-reflect:${v.scalaVersion}")
            
            add(v.configuration("embedded"), project(path: ':gtest:core', configuration: v.artifactConfiguration))
            add(v.configuration("implementation"), project(':gtest:core')) {
                capabilities {
                    requireCapability("org.elasticsearch.spark.variant:${v.getName()}")
                }
            }
            
            add(v.configuration("test", "implementation"), project(':gtest:core')) {
                capabilities {
                    requireCapability("org.elasticsearch.spark.variant:${v.getVariantName("test")}")
                }
            }
            add(v.configuration("test", "implementation"), "junit:junit:4.12")
        }

        Closure variantJarNameFixer = { Jar jar ->
            jar.archiveBaseName.set(jar.archiveBaseName.get() + "_" + v.scalaMajorVersion)
            if (!v.isDefaultVariant() && jar.archiveClassifier.get() != null) {
                String sanitizedClassifier = jar.archiveClassifier.get().replace(v.getName(), "")
                sanitizedClassifier = sanitizedClassifier.startsWith("-") ? sanitizedClassifier.substring(1) : sanitizedClassifier
                if (sanitizedClassifier.size() > 0) {
                    archiveClassifier = sanitizedClassifier
                } else {
                    archiveClassifier = null
                }
            }
        }

        project.tasks.getByName(v.taskName("jar"), variantJarNameFixer)
        project.tasks.getByName(v.taskName("javadocJar"), variantJarNameFixer)
        project.tasks.getByName(v.taskName("sourcesJar"), variantJarNameFixer)

        // embed dependent projects into the jar
        // Todo: Look into using the Shadow Plugin for this.
        // TODO: Need to find a way to ensure the jar exists, OR pull the artifact from the runtime elements config.
        project.tasks.getByName(v.taskName("jar")) { Jar jar ->
            String expected = "core-1.0-${v.getName()}.jar"

            Configuration embedded = project.getConfigurations().getByName(v.configuration("embedded"))
            jar.dependsOn(embedded)
            File coreJar = embedded.getFiles().find {expected.equals(it.name)}
            jar.from(project.zipTree(coreJar)) {
                include "org/elasticsearch/**"
                include "META-INF/services/*"
            }

//            // The default variant here does not correspond to the default variant in the core project.
//            // Create the runtime elements config name directly.
//            // Still doesn't have the jar created because Gradle doesn't know that it needs to depend on that jar being made.
//            Project coreProject = project.project(':gtest:core')
//            Configuration coreRuntimeElements = coreProject.getConfigurations().getByName(v.getName() + "RuntimeElements")
//            File coreJar = coreRuntimeElements.artifacts.file.get(0)
//            println "expected [$expected] from [$coreRuntimeElements] got [$coreJar] (Exists? ${coreJar.exists()})"
//            jar.from(zipTree(coreJar)) {
//                include "org/elasticsearch/**"
//                include "META-INF/services/*"
//            }
//
//            Configuration embeddedConfiguration = project.getConfigurations().getByName(v.configuration("embedded"))
//            List coreJars = embeddedConfiguration.collect().findAll { it.name == expected }
//            println "expected [$expected] got [$coreJars]"
//            jar.from(coreJars.collect { it.isDirectory() ? it : zipTree(it) }) {
//                include "org/elasticsearch/**"
//                include "META-INF/services/*"
//            }
        }
    }
}
