[[features]]
== Key features

The key features of {ehtm} include:

Scalable {mr} model:: {eh} is built around {mr}: _every_ operation done in {eh} results in multiple Hadoop tasks (based on the number of target shards) that interact, in parallel with {es}.

REST based:: {eh} uses {es} REST interface for communication, allowing for flexible deployments by minimizing the number of ports needed to be open within a network.

Self contained:: the library has been designed to be small and efficient. At around 300KB and _no_ extra dependencies outside Hadoop itself, distributing {eh} within your cluster is simple and fast.

Universal jar:: whether you are using vanilla Apache Hadoop or a certain distro, the _same_ {eh} jar works transparently across all of them.

Memory and I/O efficient:: {eh} is focused on performance. From pull-based parsing, to bulk updates and direct conversion to/of native types, {eh} keeps its memory and network I/O usage finely-tuned.

Adaptive I/O:: {eh} detects transport errors and retries automatically. If the {es} node died, re-routes the request to the available nodes (which are discovered automatically). Additionally, if {es} is overloaded, {eh} detects the data rejected and resents it, until it is either processed or the user-defined policy applies.

Facilitates data co-location:: {eh} fully integrates with Hadoop exposing its network access information, allowing co-located {es} and Hadoop clusters to be aware of each other and reduce network IO.

{mr} API support:: At its core, {eh} uses the low-level {mr} API to read and write data to {es} allowing for maximum integration flexibility and performance.

'old'(`mapred`) & 'new'(`mapreduce`) {mr} APIs supported:: {eh} automatically adjusts to your environment; one does not have to change between using the `mapred` or `mapreduce` APIs - both are supported, by the same classes, at the same time.

Apache Hive support:: Run Hive queries against {es} for advanced analystics and _real_time_ responses. {eh} exposes {es} as a Hive table so your scripts can crunch through data faster then ever.

Apache Pig support:: {eh} supports Apache Pig exposing {es} as a _native_ Pig `Storage`. Run your Pig scripts against {es} without any modifications to your configuration or the Pig client.

Apache Spark:: Run fast transformations directly against {es}, either by streaming data or indexing _arbitrary_ ++RDD++s. Available in both Java and Scala flavors.

Apache Storm:: {eh} supports Apache Storm exposing {es} as both a +Spout+ (source) or a +Bolt+ (sink).
