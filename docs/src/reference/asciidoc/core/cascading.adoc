[[cascading]]
== Cascading support

[quote, Cascading website]
____
http://www.cascading.org/[Cascading] is a data processing API and processing query planner used for defining, sharing, and executing data-processing workflows on a single computing node or distributed computing cluster. 
____

Cascading abstracting the {mr} API and focusing on http://docs.cascading.org/cascading/2.1/userguide/htmlch03.html[data processing] 
in terms of 'tuples' http://docs.cascading.org/cascading/2.1/userguide/htmlch03s08.html['flowing'] through http://docs.cascading.org/cascading/2.1/userguide/htmlch03s02.html[pipes] between http://docs.cascading.org/cascading/2.1/userguide/htmlch03s05.html['taps'], 
from input (called `SourceTap`) to output (named `SinkTap`). As the data flows, various operations are applied to the tuple; the whole system being transformed to {mr} operations at runtime.
With {eh}, {es} can be plugged into Cascading flows as a `SourceTap` or `SinkTap` through `EsTap`.

****
.Local or Hadoop mode?
Cascading supports two 'execution' modes or http://docs.cascading.org/cascading/2.1/userguide/htmlch03s04.html[platforms]:

Local:: for unit testing and quick POCs. Everything runs only on the local machine and file-system.
Hadoop:: production mode - connects to a proper Hadoop cluster (as oppose to the 'local' mode which is running just on the local machine).

{eh} supports *both* platforms automatically. One does not have to choose between different classes, `EsTap` can be used as both `sink` or `source`, in both modes transparently.
****

[float]
=== Installation

Just like other libraries, {eh} needs to be available in the jar classpath (either by being manually deployed in the cluster or shipped along with the Hadoop job).

[float]
=== Configuration

Cascading is configured through a `Map<Object, Object>`, typically a `Properties` object which indicates the various Cascading settings and also the application jar:

[source,java]
----
Properties props = new Properties();
AppProps.setApplicationJarClass(props, Main.class);
FlowConnector flow = new HadoopFlowConnector(props);
----

{eh} options can be specified in the same way, these being picked up automatically by all `EsTap`s down the flow:

[source,java]
----
Properties props = new Properties();
props.setProperty("es.index.auto.create", "false"); <1>
...
FlowConnector flow = new HadoopFlowConnector(props);
----

<1> set {eh} option

This approach can be used for local and remote/Hadoop flows - simply use the appropriate `FlowConnector`.

[float]
=== Type conversion

Depending on the http://docs.cascading.org/cascading/2.1/userguide/htmlch03s04.html[platform] used, Cascading can use internally either `Writable` or JDK types for its tuples. {es} handles both transparently 
(see the {mr} <<type-conversion-writable,conversion>> section) though we recommend using the same types (if possible) in both cases to avoid the overhead of maintaining two different versions.

IMPORTANT: If automatic index creation is used, please review <<auto-mapping-type-loss,this>> section for more information.

[[cascading-writing]]
[float]
=== Writing data to {es}

Simply hook, `EsTap` into the Cascading flow:

[source,java]
----
Tap in = Lfs(new TextDelimited(new Fields("id", "name", "url", "picture")), 
				"src/test/resources/artists.dat");
Tap out = new EsTap("radio/artists" <1>, new Fields("name", "url", "picture") <2>);
new HadoopFlowConnector().connect(in, out, new Pipe("write-to-Es")).complete();
----

<1> {eh} resource (index and type)
<2> Cascading tuple declaration

[float]
=== Reading data from {es}

Just the same, add `EsTap` on the other end of a pipe, to read (instead of writing) to it.

[source,java]
----
Tap in = new EsTap("radio/artists/"<1>,"?q=me*"<2>);
Tap out = new StdOut(new TextLine());
Properties cfg = new Properties();
new LocalFlowConnector().connect(in, out, new Pipe("read-from-Es")).complete();
----

<1> {eh} resource (index and type)
<2> {eh} query
